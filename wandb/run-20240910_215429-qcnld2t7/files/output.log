Model test has 798,095 trainable parameters
{'vocab_size': 15, 'context_length': 19, 'model_size': 128, 'num_heads': 8, 'num_blocks': 4, 'device': 'cuda'}
Training model from scratch
Training begin





































loss: 0.015121313333511353:  36%|████████████████████████▉                                            | 3611/10000.0 [01:16<02:14, 47.37it/s]
Traceback (most recent call last):
  File "/home/sankeerth/Gabriel/random/neural_calculator/train.py", line 184, in <module>
    main()
  File "/home/sankeerth/Gabriel/random/neural_calculator/train.py", line 179, in main
    train(model, train_dataloader, optimizer, scheduler, device, max_iter=1e4, report_interval=50, model_name=model_name)
  File "/home/sankeerth/Gabriel/random/neural_calculator/train.py", line 69, in train
    loss.backward()
  File "/home/sankeerth/miniconda3/envs/3dgs/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/sankeerth/miniconda3/envs/3dgs/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/sankeerth/miniconda3/envs/3dgs/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt