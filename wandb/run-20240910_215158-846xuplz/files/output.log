Model test has 798,095 trainable parameters
{'vocab_size': 15, 'context_length': 19, 'model_size': 128, 'num_heads': 8, 'num_blocks': 4, 'device': 'cuda'}
Training model from scratch
Training begin

















loss: 0.017466222047805787:  17%|███████████▉                                                         | 1731/10000.0 [00:35<02:50, 48.47it/s]
Traceback (most recent call last):
  File "/home/sankeerth/Gabriel/random/neural_calculator/train.py", line 182, in <module>
    main()
  File "/home/sankeerth/Gabriel/random/neural_calculator/train.py", line 177, in main
    train(model, train_dataloader, optimizer, scheduler, device, max_iter=1e4, report_interval=50, model_name=model_name)
  File "/home/sankeerth/Gabriel/random/neural_calculator/train.py", line 71, in train
    loss.backward()
  File "/home/sankeerth/miniconda3/envs/3dgs/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/sankeerth/miniconda3/envs/3dgs/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/sankeerth/miniconda3/envs/3dgs/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt